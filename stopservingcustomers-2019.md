#digitalliteracy #technology #ethics

# stop serving customers (up on a platter)

Hi there, I'm J Unrau. I used to live on Vancouver Island where I was a children's librarian, a union steward, and producer of a radio show. Now I am none of those things and live in Edmonton. 

As much as I can, I bicycle past the refineries to work as the digital literacy librarian at Strathcona County Library. My toddler in the trailer hasn't gotten frostbite or mesothelioma yet.

[Watch the video version of this talk](https://youtu.be/sXeDlDp4CPg)

# introduction

I'm here today as a public librarian who doesn't work with creating tools for library infrastructure. I'm here to talk not about a cool exciting project but to share a bit with an academic audience what library work with technology looks like on a public info desk.

# digital literacy @ scl

As a digital literacy librarian my job is part of our library's strategic plan. There's a section in there called the digital literacy strategy where part of the library's goals are to foster digital inclusion and citizenship in our county. My job is to help our library choose how we satisfy those goals. 

These choices are shaped by a number of things, including my skills and the skills of my fellow library workers, what we have the funds and staffing to provide, but also by more explicitly political concerns like protecting the library from litigation, and satisfying the world-defiling corporations that sponsor our programs (seriously, the number of Enbridge and Inter Pipeline logos we have to put on our summer reading games so we keep on getting sponsorship dollars is sickening, but that is another talk). 

But ideally they are supposed to be driven by "librarianly values" whatever those may be. [Sam Popowich wrote recently](https://redlibrarian.github.io/article/2019/08/16/constituent-power-and-intellectual-freedom.html) that Marx's [[free-development | “the free development of each as a condition for the free development of all”]] would be a good place to start. It's my thesis that the library workers helping the free development of our eaches have a lot of problems.

# a problem:

Let’s look at the kind of problems we face on the public library help desk.

It’s important to note here that when we're helping the public we aren't solely helping people connect with library resources, but the whole rest of the technological world. Like, there's the stuff the library pays for vs the rest of the internet and the things that connect to it. That second part is my job.

# can't sign into email

When you are the [[public-service | free tech help desk for the public]] you get used to explaining things you do every day without thinking. You have to explain to people why they can't access their GMail account by signing in on the library website. You have to explain about apps and ebooks and what the difference is between text messages and Facebook Messenger and [[instagram | why oh why you can't save pictures your nephew posted on instagram]].

# the problem:

So those are the kinds of problems we’re dealing with but that’s not the problem. The problem isn't that there is a lot. The problem isn't that it is too complicated or too hard for library workers to help people with all of these things. The problem we have in library technology help is the [[power imbalance]] between the library user and the gigantic corporations that are “providing” these services.

# big tech doesn't care

Part of the reason why we need to provide this help to users and hence support this [[technology-driven status quo]] is that [[opaque-system  | the system we buy into (with our money) and support (with our teaching) is opaque to our users]]. Large corporations set the rules and we teach people how to think within those systems. This is the big education project we are engaged with when we show people how to work their surveillance devices: how to be compliant with systems they don't understand.

And much like the "just add technology" theory of transparency @tanseyWhatWeDon2019 [^1] doesn't work, the "make it easier for the user" approach doesn't either. Because user-friendly doesn’t necessarily mean user-understandable, and when a for-profit tech company makes something smoother, the friction they're trying to remove is the stuff getting in the way of profit, not the stuff getting in the way of their users developing themselves and changing their societies.

[^1]: Tansey, E. (2019, October 10). What we don’t know about what we can’t see: Information and hidden infrastructure (Eira Tansey). https://www.youtube.com/watch?v=iLLFerw8R3c&feature=youtu.be


# a bigger problem:

But that expectation of ease is insidious and libraries as organizations are complicit. 

I think it's easy for us to slip into a [[customer service model]] where we're looking for a happy user at the end of our interaction. Library workers are helpful. We generally like to help. We (and our administrations especially) want our users to be happy at the end of our interaction because we were so helpful. 

# customer service 

I think people, our users at least and most likely us tech-helpers too, want things to be easy. We've trained ourselves into thinking that easier is better. It's nice to think that if we just made things look simpler then we'd have a simpler time helping people and we'd get those happy customers even more simply. That things can be simple and look simple when there are billions of dollars to be made by keeping people from understanding how the world works is naive but this is what we do.

Doing this is a choice. It's a political choice.

We can’t just be aiming for happy customers that know which icon to tap to give their lives to Facebook. We should be looking to empower them to develop themselves and further develop our world. If people feel a sense of empowerment because they learned how to update their privacy settings while still feeding their lives into the social media profit generating vortex, and they say they're more confident and happier, I think we're failing.

Don’t get me wrong, [the library freedom project](https://libraryfreedom.org/) is great, privacy education is great, but doing this kind of thing from a customer-service mindset positions us at a place where we are trying to fulfill companies’ promises of ease of use without being able to actually give our users control over what they need. What we’re doing is teaching people how to deal with being part of a system that is destroying us rather than trying to resist the system itself, to use what power we actually have to make things better.

# the biggest problem:

(beat)

# [[202204221312-capitalism]]

The problem is of course capitalism and how it's created a world where we have a few decades of livable climate left. Obviously that is the problem. And whenever us well-meaning technology helping type people show someone how to [[think like the machine]] and speak so the machine will understand us, as if that will help anything, it's at the very least not helpful for this problem.

But let’s get back to how we deal with this at our library, because that’s my job. I have this job because I can help people with their techno-woes. I can understand and explain them even if I don’t actually have the power to tear down capitalism (and my users wouldn’t want me to try). But what we can do is make things difficult.

# complications

We often joke about hoping things stay unfriendly and complicated for users because that’s our job security (in our library the example is usually Adobe Digital Editions and transferring library ebooks to Kobos), but I actually think there is something to things being complicated. When something is complicated we have to think about it. Think about how it works and why it works the way it does. Everyone here who’s written a line of code knows about that value. The Douglas Adams bit about computers’ true value is in being really dense students so the teacher needs to figure things out properly to explain them.

Yes, it is more complicated to set up a secure password manager or use Tor for browsing the internet or strip the Digital Rights Management off ebooks to put them on unsanctioned ereaders. But the simple alternatives only seem simple if everything works the way they're designed by those with power. And those designs are on keeping power away from our individuals and our societies.

But “make it more complicated” is a sentiment coming from a very privileged place. It’s my *job* to deal with this kind of thing and I shouldn’t be asking everyone in the world to be like me. So what can we do?

# [[technomoral-education]]

This is something I had a lot of trouble with earlier in my library career before reading Shannon Vallor’s book *Technology and the Virtues* [^2] (which I found through the [Librarianshipwreck blog](https://librarianshipwreck.wordpress.com/2017/08/24/living-well-in-the-technosocial-world-a-review-of-shannon-vallors-technology-and-the-virtues/)). Vallor’s book is a summary of Aristotelean and Buddhist and Confucian [[virtue ethics]] and how we could use them to lead a moral life in a technologically mediated world.

Virtue ethics assume that you can't just make a simple rule to follow and remember because the world and its circumstances constantly change and we need to approach situations *specifically*. One of the big things is to cultivate good habits and approaches that can be applied flexibly to the changing situation of life.

This means we use examples of people dealing with the messy complexity of working with and making decisions in this world.

[^2]: Vallor, S. (2016). Technology and the virtues: A philosophical guide to a future worth wanting. Oxford University Press.



# what does that look like?

So Toronto Public Library does a big digital privacy week shebang. I think that’s great, but in my opinion doing a big event focused on one ethical issue is not as important as infusing it into our regular offerings.

At our library we do somewhere around 15 hours each month teaching digital literacy classes and spend about 25 hours each month doing one on one tech help. Our Online Privacy Tools, Cloud Computing and Password Tools classes are regular offerings that we've designed around principles of Vallor's technomoral education (including cross-contextual habituation, studying exemplars and practicing skills of discernment). We also do our best to incorporate these kinds of teachings into our Getting Started With.. the different operating system classes.

My coworkers and I can disagree on the value of things like privacy education for our users (who are mostly white senior citizens that are pretty well-off), but one of the things we do our best to talk about is how we as library workers who’ve had time to research and think about technology in a way that lets us teach it how we use technology. This leaves things up to individual instructors who sometimes will err on the side of expediency. But this has also led to my colleague offering a class called Intro to Voice Assistants in which we just squick everyone out about the gadget their well-meaning relative gave them.

What I haven’t been able to do is make change at the institutional level[^3]. A topical example: 

[^3]: [[202006301221-marginalized-christianity]]


# lynda -> linkedin learning

Do you know what Lynda.com is? It's a site full of instructional videos that have some quality control and are organized with at least a bit of knowledge of pedagogical theory. It’s a resource that’s really good for learning about the tools white-collar businessish people use. If your library had a subscription you could login with your library barcode number and learn all about Pivot Tables and nonlinear video editing without needing to pay to subscribe yourself.

So Microsoft bought LinkedIn which bought Lynda (I don't know the order) and this fall they were planning to transition libraries over to using LinkedIn Learning instead of Lynda.

Of course LinkedIn touted changes as making things easier for our users (now they can use the app which library logins couldn’t before) but the now library users couldn’t just sign in with a library barcode and PIN (which I am aware isn’t great anyways with SIP2 authentication but whatever) but needed to create a LinkedIn social media account. Which, by default would be indexed by Google. To watch videos the library is paying for. 

If you believe Jaron Lanier (of *Ten Reasons to Delete Your Social Media Accounts Right Now* @lanierTenArgumentsDeleting2018) LinkedIn isn’t the worst of the social media companies, but if you believe Shoshana Zuboff (of *The Age of Surveillance Capitalism* @zuboffAgeSurveillanceCapitalism2019) you’re probably pretty leery of Microsoft feeding all this detail how your library users are educating themselves into their AI projects.

So I don’t know what we should be doing as technomoral exemplars in this case. I mean, I know we shouldn’t just be saying “Welp. That’s the way of the world now” and throwing our library users to the tender mercies of social media, but I also know that I will have very little institutional support for getting our IT staff to build a tool that could expropriate all the videos from Lynda.com and host them on our own servers so users wouldn't be exposed to all that. Although really, that'd be an awesome service to provide. 

At our organization the plan has been to educate people how to change their privacy settings so they aren’t websearchable. To me this is fundamentally flawed and putting the onus on us as educators and the public as users rather than on the company. I would much rather take the approach of building the kind of future we want by not paying for the kind we don’t want, but I am not the kind of librarian anyone trusts with vendor negotiations.

Apparently the Lynda-LinkedIn changeover has now been delayed but not through any heroic action on our part.

# digital literacy & agriculture

I'm ending with a bit from Wendell Berry in *Unsettling America*. Mostly because I like the parallel between the challenges of big technology in [[human-scale farming]] and in human-scale library work.

>“It is an old story. Evil is offering us the world: “All these things will I give thee, if thou wilt fall down and worship me.” And we have only the old paradox for an answer: If we accept all on that condition, we lose all. What is new is the guise of the evil: a limitless technology, dependent upon a limitless morality, which is to say upon no morality at all. - Wendell Berry, Unsettling America @berryUnsettlingAmericaCulture1997 

So here we are, stuck in a status quo that pretends to be simple because that is what is profitable for others, not what is of value. A shallow education in "what works" is a matter of throwing people into a thresher, not providing them meaningful ways to develop themselves and their communities. It's our job to be reflective critical and resistant and stop making it easy for those limitless appetites to devour everything.

# thank you

Thank you to Sam Popowich and Emily Drabinski both of whose work has inspired a lot of my thinking around these issues. Also to Tricia Reese for being great at helping to implement these ideas.
